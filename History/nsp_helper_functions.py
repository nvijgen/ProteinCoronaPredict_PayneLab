{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN6YEHJ62uRbO9IAmMJg2Ug"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","import pandas as pd\n","import json\n","import urllib.request\n","import numpy as np\n","\n","\n","def uniprot_data_scraping(uniprot_list, data_to_pull='standard'):\n","    # Pull in lookup codes\n","    query_lookup_table = pd.read_excel('/content/drive/MyDrive/Predicting_the_Protein_Corona_Vijgen/support_files/query_lookup_table.xlsx', header=0)\n","\n","    # Identify the columns that we want to search for\n","    if data_to_pull == 'standard': # standard columns\n","        data_to_pull = ['Entry', 'Protein names', 'Status', 'Protein families', 'Length',\n","       'Mass', 'Sequence', 'Binding site', 'Calcium binding', 'DNA binding',\n","       'Metal binding', 'Nucleotide binding', 'Site', 'Function [CC]',\n","       'Absorption', 'Active site',\n","       'Catalytic activity', 'Cofactor', 'EC number', 'Kinetics', 'Pathway',\n","       'pH dependence', 'Redox potential', 'Rhea Ids',\n","       'Temperature dependence', 'Interacts with', 'Subunit structure [CC]',\n","       'Induction', 'Tissue specificity', 'Gene ontology (biological process)',\n","       'Gene ontology (GO)', 'Gene ontology (molecular function)',\n","       'Gene ontology IDs', 'ChEBI', 'ChEBI (Catalytic activity)',\n","       'ChEBI (Cofactor)', 'ChEBI IDs', 'Intramembrane',\n","       'Subcellular location [CC]', 'Transmembrane', 'Topological domain',\n","       'Chain', 'Cross-link', 'Disulfide bond', 'Glycosylation',\n","       'Initiator methionine', 'Lipidation', 'Modified residue', 'Peptide',\n","       'Propeptide', 'Post-translational modification', 'Signal peptide',\n","       'Transit peptide', 'Beta strand', 'Helix', 'Turn', 'Coiled coil',\n","       'Compositional bias', 'Domain [CC]', 'Domain [FT]', 'Motif', 'Region',\n","       'Repeat', 'Zinc finger']\n","\n","    elif data_to_pull == 'all': # all columns that we have keys for\n","        data_to_pull=query_lookup_table['Column names as displayed on website'].values\n","\n","    elif type(data_to_pull) == list: # specific names that we can lookup\n","        data_to_pull = data_to_pull # do nothing\n","\n","    else: # doesnt fit the specified values\n","        raise ValueError('Change data_to_pull to \"any\", \"standard\" or a list of column names')\n","\n","\n","    col_string = '' #create the search column string\n","    first_pass=True\n","    for col in data_to_pull: # connect together the columns that need to be separated by commas\n","        if first_pass:\n","            col_string = query_lookup_table.loc[query_lookup_table['Column names as displayed on website'] == col,\n","                                 'Column names as displayed in URL'].values[0]\n","            first_pass = False\n","\n","        else:\n","            try: col_string += ','+query_lookup_table.loc[query_lookup_table['Column names as displayed on website'] == col,\n","                                 'Column names as displayed in URL'].values[0]\n","\n","            except: print(f\"Could not find URL Name for {col}\")\n","\n","    col_string = col_string.replace(' ', '%20') #get rid of spaces\n","\n","    # create prefix and suffix to web address\n","    query_string_suffix= \"&format=tab&columns=\"+col_string\n","    query_string_prefix='https://www.uniprot.org/uniprot/?query='\n","\n","    first_pass=True\n","    for uniprot in uniprot_list: #go through list of all proteins\n","        if first_pass: # initialize the dataframe\n","            try:\n","                total_data = pd.read_csv(query_string_prefix+uniprot+query_string_suffix, sep='\\t',  thousands=',') # get data\n","\n","                if total_data.shape[0] > 1: # Only take correct row, sometimes UniProt sends back more than 1 response\n","                    total_data = total_data.loc[total_data.Entry==uniprot]\n","                first_pass = False # dont come back here\n","\n","            except:\n","                print(f\"Could not complete URL request for {uniprot}\")\n","\n","\n","        else:\n","            try:\n","                revolve_data = pd.read_csv(query_string_prefix+uniprot+query_string_suffix, sep='\\t',  thousands=',') # get data\n","\n","                if revolve_data.shape[0] > 1: # Only take correct row, sometimes UniProt sends back more than 1 response\n","                    revolve_data = revolve_data.loc[revolve_data.Entry==uniprot]\n","                    print(revolve_data.shape)\n","                total_data = total_data.append(revolve_data, ignore_index=True)\n","\n","            except:\n","                print(f\"Could not complete URL request for {uniprot}\")\n","\n","\n","\n","    total_data=total_data.fillna(0) # fill nans with zeros\n","\n","    return total_data\n","\n","def protein_data_scraping_fasta(accession_number):\n","    \"\"\"\n","        Searches the interpro database based on the uniprot accession number and returns a JSON with the found data.\n","        Designed to suppress errors but print that it found one.\n","\n","        :param accession_number: Uniprot accession number as a string\n","        :type accession_number: str\n","\n","        :return: FASTA data as a Sting\n","    \"\"\"\n","\n","    # url for API\n","    base_url = 'https://www.uniprot.org/uniprot/'\n","    accession_number = accession_number.replace(' ', '')\n","    current_url = base_url + accession_number + '.fasta'\n","    print(current_url)\n","\n","    try:\n","        # Fetch data\n","        with urllib.request.urlopen(current_url) as url:\n","            data = url.read().decode()\n","            return data\n","\n","    except json.JSONDecodeError:  # if data cant be found just pass it\n","        print(f'Data not found for {accession_number} (Decode error)')\n","        return None\n","\n","def netsurfp_1point1_data_processing(unique_id_list, complete_netsurfp_df):\n","    first_pass=True\n","    for i in unique_id_list:\n","\n","        # get correct values\n","        boolarray = complete_netsurfp_df['sequence name'].str.contains(i)\n","        filtered = complete_netsurfp_df[boolarray]\n","\n","        # total amino acids\n","        total_aa = filtered.shape[0]\n","\n","        #count exposed residues\n","        exposed = filtered[filtered['class assignment'] == 'E']\n","        exposed_count = exposed.shape[0]\n","        if total_aa == 0:\n","            print(i)\n","            frac_exposed=0\n","        else:\n","            frac_exposed = exposed_count / total_aa\n","\n","        aa_dict = {'A':0, 'C':0, 'D':0, 'E':0, 'F':0, 'G':0, 'H':0,\n","                'I':0, 'K':0, 'L':0, 'M':0, 'N':0, 'P':0, 'Q':0,\n","                'R':0, 'S':0, 'T':0, 'V':0, 'W':0, 'Y':0}\n","\n","        if frac_exposed == 0: # bypass any that have had no exposed amino acids\n","            aa_exposed_frac = 0\n","\n","        else:\n","            for j in exposed['amino acid']: # go through and count what needs to be added\n","                aa_dict[j] += 1\n","\n","            aa_exposed_frac_total = {'fraction_total_exposed_'+key: value / total_aa for key, value in aa_dict.items()}\n","            aa_exposed_frac_exposed = {'fraction_exposed_exposed_'+key: value / exposed_count for key, value in aa_dict.items()}\n","\n","        nonpolar_aa = ['A', 'F', 'G', 'I', 'L', 'M', 'P', 'V', 'W']\n","        nonpolar_counts = 0\n","        for k in nonpolar_aa:\n","            nonpolar_counts += aa_dict[k]\n","\n","        if nonpolar_counts == 0:\n","            nonpolar_exposed_frac = 0\n","        else:\n","            nonpolar_exposed_frac_exposed = nonpolar_counts / exposed_count\n","            nonpolar_exposed_frac_total = nonpolar_counts / total_aa\n","\n","        data_to_update ={'entry': i, 'fraction_exposed':np.around(frac_exposed, 3), 'fraction_buried': np.around(1-frac_exposed, 3),\n","                        'fraction_exposed_nonpolar_total':nonpolar_exposed_frac_total,\n","                        'fraction_exposed_nonpolar_exposed':nonpolar_exposed_frac_exposed,\n","                        \"rsa_mean\": np.around(filtered['relative surface accessibility'].mean(), 3),\n","                        \"rsa_median\": np.around(filtered['relative surface accessibility'].median(), 3),\n","                        \"rsa_std\": np.around(filtered['relative surface accessibility'].std(), 3),\n","                        \"asa_sum\": np.around(filtered['absolute surface accessibility'].sum(), 3),\n","                        **aa_exposed_frac_total, **aa_exposed_frac_exposed}\n","\n","\n","        if first_pass:\n","            netsurfp_processed_data = pd.DataFrame()\n","            netsurfp_processed_data = pd.DataFrame.from_dict(data_to_update, orient='index').transpose()\n","            first_pass = False\n","\n","        else:\n","            netsurfp_processed_data = netsurfp_processed_data.append(pd.DataFrame.from_dict(data_to_update, orient='index').transpose(), ignore_index=True)\n","\n","\n","    return netsurfp_processed_data\n","\n","def netsurfp_2_data_processing(unique_id_list, complete_netsurfp_df):\n","    first_pass=True\n","    for i in unique_id_list:\n","        # print('hi')\n","        # get correct values\n","        boolarray = complete_netsurfp_df['id'].str.contains(i)\n","        filtered = complete_netsurfp_df[boolarray]\n","        filtered['class assignment'] = np.where(filtered.rsa > 0.25, 'E', 'B')\n","        # total amino acids\n","        total_aa = filtered.shape[0]\n","\n","        #count exposed residues\n","        exposed = filtered[filtered['class assignment'] == 'E']\n","        exposed_count = exposed.shape[0]\n","        if total_aa == 0:\n","            print('Error at ',i)\n","\n","            frac_exposed=0\n","            frac_buried = 0\n","\n","        else:\n","            frac_exposed = exposed_count / total_aa\n","            frac_buried = 1-frac_exposed\n","\n","        aa_dict = {'A':0, 'C':0, 'D':0, 'E':0, 'F':0, 'G':0, 'H':0,\n","                'I':0, 'K':0, 'L':0, 'M':0, 'N':0, 'P':0, 'Q':0,\n","                'R':0, 'S':0, 'T':0, 'V':0, 'W':0, 'Y':0}\n","\n","        if frac_exposed == 0: # bypass any that have had no exposed amino acids\n","            aa_exposed_frac = 0\n","            aa_exposed_frac_total = {'fraction_total_exposed_'+key: 0 for key, value in aa_dict.items()}\n","            aa_exposed_frac_exposed = {'fraction_exposed_exposed_'+key: 0 for key, value in aa_dict.items()}\n","\n","        else:\n","            for j in exposed['seq']: # go through and count what needs to be added\n","                aa_dict[j] += 1\n","\n","            aa_exposed_frac_total = {'fraction_total_exposed_'+key: value / total_aa for key, value in aa_dict.items()}\n","            aa_exposed_frac_exposed = {'fraction_exposed_exposed_'+key: value / exposed_count for key, value in aa_dict.items()}\n","\n","        nonpolar_aa = ['A', 'F', 'G', 'I', 'L', 'M', 'P', 'V', 'W']\n","        nonpolar_counts = 0\n","        for k in nonpolar_aa:\n","            nonpolar_counts += aa_dict[k]\n","\n","        if nonpolar_counts == 0:\n","            nonpolar_exposed_frac_exposed = 0\n","            nonpolar_exposed_frac_total = 0\n","\n","        else:\n","            nonpolar_exposed_frac_exposed = nonpolar_counts / exposed_count\n","            nonpolar_exposed_frac_total = nonpolar_counts / total_aa\n","\n","        polar_exposed_frac_exposed = (exposed_count-nonpolar_counts) / exposed_count\n","        polar_exposed_frac_total = (total_aa-nonpolar_counts) / total_aa\n","\n","        data_to_update ={'entry': i, 'fraction_exposed':np.around(frac_exposed, 3), 'fraction_buried': np.around(frac_buried, 3),\n","                        'fraction_exposed_nonpolar_total':nonpolar_exposed_frac_total,\n","                        'fraction_exposed_nonpolar_exposed':nonpolar_exposed_frac_exposed,\n","                        'fraction_exposed_polar_total':polar_exposed_frac_total,\n","                        'fraction_exposed_polar_exposed':polar_exposed_frac_exposed,\n","                        \"rsa_mean\": np.around(filtered['rsa'].mean(), 3),\n","                        \"rsa_median\": np.around(filtered['rsa'].median(), 3),\n","                        \"rsa_std\": np.around(filtered['rsa'].std(), 3),\n","                        \"asa_sum\": np.around(filtered['asa'].sum(), 3),\n","                        **aa_exposed_frac_total, **aa_exposed_frac_exposed,\n","                        'nsp_secondary_structure_coil':np.around(np.sum(np.where(filtered.q3.str.contains('C'), True, False))/filtered.shape[0], 3),\n","                        'nsp_secondary_structure_sheet':np.around(np.sum(np.where(filtered.q3.str.contains('E'), True, False))/filtered.shape[0], 3),\n","                        'nsp_secondary_structure_helix':np.around(np.sum(np.where(filtered.q3.str.contains('H'), True, False))/filtered.shape[0], 3),\n","                        'nsp_disordered':np.around(np.sum(filtered.disorder.to_numpy() >= 0.5)/filtered.shape[0],3)}\n","\n","\n","        if first_pass:\n","            netsurfp_processed_data = pd.DataFrame()\n","            netsurfp_processed_data = pd.DataFrame.from_dict(data_to_update, orient='index').transpose()\n","            first_pass = False\n","\n","        else:\n","            netsurfp_processed_data = netsurfp_processed_data.append(pd.DataFrame.from_dict(data_to_update, orient='index').transpose(), ignore_index=True)\n","\n","\n","    return netsurfp_processed_data\n","\n","if __name__ == \"__main__\":\n","    test_df = uniprot_data_scraping(['P61823'],data_to_pull='standard')\n","    print(test_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":358},"id":"Wg52aRAwSwn7","executionInfo":{"status":"error","timestamp":1715866591019,"user_tz":240,"elapsed":22426,"user":{"displayName":"Nicole Vijgen","userId":"15751869298741229715"}},"outputId":"d57ab4fc-74a9-4362-fa8d-7a9383afd9be"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Could not complete URL request for P61823\n"]},{"output_type":"error","ename":"UnboundLocalError","evalue":"local variable 'total_data' referenced before assignment","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d8ee9cd7de5a>\u001b[0m in \u001b[0;36m<cell line: 274>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniprot_data_scraping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'P61823'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_to_pull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'standard'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-d8ee9cd7de5a>\u001b[0m in \u001b[0;36muniprot_data_scraping\u001b[0;34m(uniprot_list, data_to_pull)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mtotal_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fill nans with zeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'total_data' referenced before assignment"]}]}]}
