{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1TjY6xFBQnUzyZ9vFH6Fg9x6fwYVtCN_l","authorship_tag":"ABX9TyOoVDdad4gxXDK4oV8rx99J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Import Statements\n","--"],"metadata":{"id":"amcrLmkmKjkH"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MIdgZwW1RCQ3","executionInfo":{"status":"ok","timestamp":1725668834460,"user_tz":240,"elapsed":18038,"user":{"displayName":"Nicole","userId":"15751869298741229715"}},"outputId":"4e77861d-8f35-4a72-b11c-f49c577fa41a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import csv\n","import numpy as np\n","import scipy #as stats\n","import re\n","from scipy import stats\n","from scipy.stats import trim_mean"],"metadata":{"id":"0owhDWqbsg65"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_string(input_string):\n","    input_string = input_string.replace('\\r', '')  # Remove '\\r' from input_string\n","    pattern = r'(?:sp\\|)?([^|\\r]+)'\n","    match = re.search(pattern, input_string)\n","    if match:\n","        return match.group(1)\n","    else:\n","        return None\n","\n","def drop_after_semicolon(input_string):\n","    if \";\" in input_string:\n","        return input_string.split(\";\")[0]\n","    else:\n","        return input_string"],"metadata":{"id":"4YsI-gxcsuwV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Remove carriage return character from Perseus text file"],"metadata":{"id":"JAZFsHct3wZe"}},{"cell_type":"code","source":["# Load the file\n","file_path = '/content/drive/MyDrive/Predicting_the_Protein_Corona_Vijgen/Input_Data/Proteomics/Perseus_Files/Bov_SP_06252024_Pers.txt'\n","data = pd.read_csv(file_path, sep='\\t', lineterminator='\\n')"],"metadata":{"id":"BG5b6FCV3wLn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pa674p5EtDon","executionInfo":{"status":"ok","timestamp":1725669084995,"user_tz":240,"elapsed":209,"user":{"displayName":"Nicole","userId":"15751869298741229715"}},"outputId":"62b851ff-5d03-46bd-dfbd-8d77c37e1301"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Intensity 31_200_PS Carb_10', 'Intensity 32_200_PS Carb_100',\n","       'Intensity 33_small_Citrate_10', 'Intensity 34_large_Citrate_10',\n","       'Intensity 35_small_PEI_10', 'Intensity 36_large_PEI_10',\n","       'Intensity 37_large_PVP@AU_100', 'Intensity 38_small_PVP@AU_10',\n","       'Intensity 39_small_PVP@AU_100', 'Intensity 40_large_Citrate_100',\n","       'Intensity 41_large_PEI_100', 'Intensity 42_small_Citrate_100',\n","       'Intensity 43_small_PEI_100', 'Intensity 44_large_PVP@AU_10',\n","       'Intensity 45_large_PEG@Au_100', 'Intensity 46_large_PEI@Au_100',\n","       'Intensity 47_small_PEI@Au_100', 'Intensity 48_200_PS Carb@ PEG_100',\n","       'Intensity 49_200_PS Carb@ PEG_100', 'Intensity 50_FBS',\n","       'Intensity 51_SPQC1', 'Intensity 52_SPQC2', 'Intensity 53_SPQC3',\n","       'iBAQ 31_200_PS Carb_10', 'iBAQ 32_200_PS Carb_100',\n","       'iBAQ 33_small_Citrate_10', 'iBAQ 34_large_Citrate_10',\n","       'iBAQ 35_small_PEI_10', 'iBAQ 36_large_PEI_10',\n","       'iBAQ 37_large_PVP@AU_100', 'iBAQ 38_small_PVP@AU_10',\n","       'iBAQ 39_small_PVP@AU_100', 'iBAQ 40_large_Citrate_100',\n","       'iBAQ 41_large_PEI_100', 'iBAQ 42_small_Citrate_100',\n","       'iBAQ 43_small_PEI_100', 'iBAQ 44_large_PVP@AU_10',\n","       'iBAQ 45_large_PEG@Au_100', 'iBAQ 46_large_PEI@Au_100',\n","       'iBAQ 47_small_PEI@Au_100', 'iBAQ 48_200_PS Carb@ PEG_100',\n","       'iBAQ 49_200_PS Carb@ PEG_100', 'iBAQ 50_FBS', 'iBAQ 51_SPQC1',\n","       'iBAQ 52_SPQC2', 'iBAQ 53_SPQC3', 'Top3 31_200_PS Carb_10',\n","       'Top3 32_200_PS Carb_100', 'Top3 33_small_Citrate_10',\n","       'Top3 34_large_Citrate_10', 'Top3 35_small_PEI_10',\n","       'Top3 36_large_PEI_10', 'Top3 37_large_PVP@AU_100',\n","       'Top3 38_small_PVP@AU_10', 'Top3 39_small_PVP@AU_100',\n","       'Top3 40_large_Citrate_100', 'Top3 41_large_PEI_100',\n","       'Top3 42_small_Citrate_100', 'Top3 43_small_PEI_100',\n","       'Top3 44_large_PVP@AU_10', 'Top3 45_large_PEG@Au_100',\n","       'Top3 46_large_PEI@Au_100', 'Top3 47_small_PEI@Au_100',\n","       'Top3 48_200_PS Carb@ PEG_100', 'Top3 49_200_PS Carb@ PEG_100',\n","       'Top3 50_FBS', 'Top3 51_SPQC1', 'Top3 52_SPQC2', 'Top3 53_SPQC3',\n","       'Species', 'Only identified by site', 'Reverse',\n","       'Potential contaminant', 'Taxonomy IDs', 'Majority protein IDs\\r'],\n","      dtype='object')"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Remove the extra whitespace from column names\n","data.columns = data.columns.str.strip()\n","\n","# Replace NaN values with zero\n","data.fillna(0, inplace=True)\n","\n","# Apply extract_string function\n","data['Majority protein IDs'] = data['Majority protein IDs'].apply(extract_string)\n","\n","# Apply drop_after_semicolon function\n","data['Majority protein IDs'] = data['Majority protein IDs'].apply(drop_after_semicolon)\n","\n","# Filter columns and perform data concatenation\n","# samples = df.filter(like='Intensity ').copy()  # options are: 'Intensity ', 'Top3 ', 'iBAQ '\n","# text_columns = ['Majority protein IDs']\n","# text = df[text_columns].copy()\n","# data = pd.concat([samples, text], axis=1)\n","\n","\n","# Print the resulting DataFrame columns\n","print(data.columns)\n","\n","# Display the first 25 rows of the resulting DataFrame\n","#print(data.head(25))\n","print(data['Majority protein IDs'].head(50))\n","\n","\n","# Save the updated DataFrame to a new file\n","data.to_csv('/content/drive/MyDrive/Predicting_the_Protein_Corona_Vijgen/Input_Data/Proteomics/Perseus_Files/Updated/Bov_SP_06252024_Pers.txt', sep='\\t', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VjQ-vkOLAF5l","executionInfo":{"status":"ok","timestamp":1725669200231,"user_tz":240,"elapsed":186,"user":{"displayName":"Nicole","userId":"15751869298741229715"}},"outputId":"e48296b3-30d2-464e-b88c-cffd555c6a9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Intensity 31_200_PS Carb_10', 'Intensity 32_200_PS Carb_100',\n","       'Intensity 33_small_Citrate_10', 'Intensity 34_large_Citrate_10',\n","       'Intensity 35_small_PEI_10', 'Intensity 36_large_PEI_10',\n","       'Intensity 37_large_PVP@AU_100', 'Intensity 38_small_PVP@AU_10',\n","       'Intensity 39_small_PVP@AU_100', 'Intensity 40_large_Citrate_100',\n","       'Intensity 41_large_PEI_100', 'Intensity 42_small_Citrate_100',\n","       'Intensity 43_small_PEI_100', 'Intensity 44_large_PVP@AU_10',\n","       'Intensity 45_large_PEG@Au_100', 'Intensity 46_large_PEI@Au_100',\n","       'Intensity 47_small_PEI@Au_100', 'Intensity 48_200_PS Carb@ PEG_100',\n","       'Intensity 49_200_PS Carb@ PEG_100', 'Intensity 50_FBS',\n","       'Intensity 51_SPQC1', 'Intensity 52_SPQC2', 'Intensity 53_SPQC3',\n","       'iBAQ 31_200_PS Carb_10', 'iBAQ 32_200_PS Carb_100',\n","       'iBAQ 33_small_Citrate_10', 'iBAQ 34_large_Citrate_10',\n","       'iBAQ 35_small_PEI_10', 'iBAQ 36_large_PEI_10',\n","       'iBAQ 37_large_PVP@AU_100', 'iBAQ 38_small_PVP@AU_10',\n","       'iBAQ 39_small_PVP@AU_100', 'iBAQ 40_large_Citrate_100',\n","       'iBAQ 41_large_PEI_100', 'iBAQ 42_small_Citrate_100',\n","       'iBAQ 43_small_PEI_100', 'iBAQ 44_large_PVP@AU_10',\n","       'iBAQ 45_large_PEG@Au_100', 'iBAQ 46_large_PEI@Au_100',\n","       'iBAQ 47_small_PEI@Au_100', 'iBAQ 48_200_PS Carb@ PEG_100',\n","       'iBAQ 49_200_PS Carb@ PEG_100', 'iBAQ 50_FBS', 'iBAQ 51_SPQC1',\n","       'iBAQ 52_SPQC2', 'iBAQ 53_SPQC3', 'Top3 31_200_PS Carb_10',\n","       'Top3 32_200_PS Carb_100', 'Top3 33_small_Citrate_10',\n","       'Top3 34_large_Citrate_10', 'Top3 35_small_PEI_10',\n","       'Top3 36_large_PEI_10', 'Top3 37_large_PVP@AU_100',\n","       'Top3 38_small_PVP@AU_10', 'Top3 39_small_PVP@AU_100',\n","       'Top3 40_large_Citrate_100', 'Top3 41_large_PEI_100',\n","       'Top3 42_small_Citrate_100', 'Top3 43_small_PEI_100',\n","       'Top3 44_large_PVP@AU_10', 'Top3 45_large_PEG@Au_100',\n","       'Top3 46_large_PEI@Au_100', 'Top3 47_small_PEI@Au_100',\n","       'Top3 48_200_PS Carb@ PEG_100', 'Top3 49_200_PS Carb@ PEG_100',\n","       'Top3 50_FBS', 'Top3 51_SPQC1', 'Top3 52_SPQC2', 'Top3 53_SPQC3',\n","       'Species', 'Only identified by site', 'Reverse',\n","       'Potential contaminant', 'Taxonomy IDs', 'Majority protein IDs'],\n","      dtype='object')\n","0          T\n","1     A2I7M9\n","2     A2I7N0\n","3     A2I7N1\n","4     A2I7N2\n","5     A2I7N3\n","6     A2VE23\n","7     A2VE99\n","8     Q58DS5\n","9     Q5E9E2\n","10    A5D7B7\n","11    A5D7D1\n","12    A5D7I4\n","13    A5D989\n","14    A5PKI3\n","15    A6H767\n","16    A6H768\n","17    A6QNT4\n","18    A6QPQ2\n","19    A6QQF6\n","20    A6QR46\n","21    A7E3W2\n","22    A7MB62\n","23    A7MBJ5\n","24    C0HLN2\n","25    E1BF81\n","26    F1N152\n","27    G3MYZ3\n","28    G3X745\n","29    O02659\n","30    O18738\n","31    O18739\n","32    O18979\n","33    O46375\n","34    O46414\n","35    O46415\n","36    O46470\n","37    O62644\n","38    O77742\n","39    O77783\n","40    O77834\n","41    O97680\n","42    P00432\n","43    P00515\n","44    P00735\n","45    P00741\n","46    P00743\n","47    P00744\n","48    P00745\n","49    P00978\n","Name: Majority protein IDs, dtype: object\n"]}]},{"cell_type":"code","source":["quant_method = ['Intensity '] #'iBAQ ', 'Top3 '\n","text_columns = ['Majority protein IDs']\n","uniprot_type = [' Swiss'] #' Swiss + TrEMBLE'\n","\n","for i in quant_method:\n","    # Set Uniprot Database file based on uniprot_type; Swiss-Prot or Swiss-Prot + TrEMBLE\n","    uniprot_file = uniprot_type[0]  # Adjust index as needed\n","    prot_file = '/content/drive/MyDrive/Predicting_the_Protein_Corona_Vijgen/Input_Data/Proteomics/Uniprot_Files/Bovine_swiss_05_04_24.xlsx'\n","\n","    # Extract filename from the file path\n","    filename = os.path.basename(prot_file)\n","    print(filename) # print to verify\n","\n","    # Perseus txt file (from Updated subfolder):\n","    data = pd.read_csv('/content/drive/MyDrive/Predicting_the_Protein_Corona_Vijgen/Input_Data/Proteomics/Perseus_Files/Updated/Bov_SP_06252024_Pers.txt', sep='\\t', lineterminator='\\n')\n","\n","    # Remove the extra whitespace from column names\n","    data.columns = data.columns.str.strip()\n","\n","    # Uniprot Database file:\n","    prot_details = pd.read_excel(prot_file)\n","    identifier = filename[:3] + uniprot_file + ' ' + i\n","    print(identifier) # print to verify\n","\n","    # Drop weird row from MQ text file\n","    data = data.drop([0]) # unsure about this line - maybe it is removing the column headers?\n","    samples = data.filter(like=i)\n","    text = data[text_columns]\n","    # Drop all columns that are not pertinent from Perseus output\n","    data = pd.concat([text, samples], axis=1)\n","    # DATA PARSING Section\n","    zero_replace = 1 * (10 ** 5)\n","\n","    # Preprocess 'Majority protein IDs' column to handle float values\n","    data['Majority protein IDs'] = data['Majority protein IDs'].astype(str)\n","\n","    # Apply extract_string function\n","    data['Majority protein IDs'] = data['Majority protein IDs'].apply(extract_string)\n","\n","    data = data.rename(columns={'Majority protein IDs': 'Entry'})\n","    # Join Protein Names from the protein IDs\n","    inner_join = data.merge(prot_details, left_on='Entry', right_on='Entry', how='left', suffixes=('_left', '_right'))\n","    inner_join.to_csv('merge.csv')\n","    data.insert(1, 'MW', inner_join['Mass'].values)\n","    data.insert(1, 'prot', inner_join['Protein names'].values)\n","    #data.insert(1, 'GO', inner_join['Gene ontology (biological process)'].values) # can uncomment if pulling this info from Uniprot database\n","    data.insert(1, 'prot2', data['prot'].str.split(\"(\").str[0])\n","    data['prot2'] = data['prot2'].str.split(\"[\").str[0]\n","    data['prot'].replace('', np.nan, inplace=True)\n","    data.dropna(subset=['prot'], inplace=True)\n","\n","\n","    # DATA CALCULATIONS and SORTING\n","    descriptor_cols = 4\n","\n","    # Convert data to float where necessary\n","    data_norm = data.copy()\n","    data_norm.iloc[:, descriptor_cols:] = data_norm.iloc[:, descriptor_cols:].astype(float)\n","\n","    # Normalizing using Trimmean\n","    for col in data_norm.columns[descriptor_cols:]:\n","        current_trimmean = trim_mean(data_norm[col], 0.1)\n","        if current_trimmean == 0:\n","            current_trimmean = 1\n","        data_norm[col] /= current_trimmean\n","\n","    # Scaling data after normalizing\n","    scale_factor = 100\n","    for col in data_norm.columns[descriptor_cols:]:\n","        mean_val = data_norm[col].mean()\n","        if mean_val != 0:  # Avoid division by zero\n","            data_norm[col] = (data_norm[col] / mean_val) * scale_factor\n","\n","    # Turn into Percent\n","    for col in data_norm.columns[descriptor_cols:]:\n","        total = data_norm[col].sum()\n","        if total != 0:  # Avoid division by zero\n","            data_norm[col] = (data_norm[col] / total) * scale_factor\n","\n","    # Sort by average\n","    data_norm_out = data_norm.copy()\n","    data_norm_out['avg'] = data_norm_out.iloc[:, descriptor_cols:].mean(axis=1)\n","    data_norm_out.sort_values('avg', ascending=False, inplace=True)\n","    data_norm_out.drop(columns=['avg'], inplace=True)\n","\n","    # Rename columns based on 'i' length from your loop, adjust if 'i' is defined elsewhere\n","    x = len(i)\n","    for col in data_norm_out.columns[descriptor_cols:]:\n","        tmp = col[x:x+2]\n","        data_norm_out.rename(columns={col: tmp}, inplace=True)\n","\n","    # Save the processed data NEED TO CHANGE FILE PATH MOVING FORWARD\n","    data_norm_out.to_csv(f'/content/drive/MyDrive/Predicting_the_Protein_Corona_Vijgen/Input_Data/Proteomics/Abundance_Files/test/{identifier}_v2.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fE04m8o-CEQZ","executionInfo":{"status":"ok","timestamp":1725669273384,"user_tz":240,"elapsed":2911,"user":{"displayName":"Nicole","userId":"15751869298741229715"}},"outputId":"56734060-f494-45d9-cd74-ec91af7cc4a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Bovine_swiss_05_04_24.xlsx\n","Bov Swiss Intensity \n"]}]}]}