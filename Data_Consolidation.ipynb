{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data Consolidation Notebook\n","\n","\n","\n","---\n","\n","\n","\n","This notebook merges the following data:\n","\n","\n","*   Proteomic abundance values\n","*   Control protein abundance values\n","*   NetSurfP protein calculations\n","*   BioPython protein calculations\n","*   Nanoparticle properties\n","*   Wet lab experimental conditions\n","\n","The result is an excel file that is used in the RFR and RFC code notebooks.\n"],"metadata":{"id":"uvddj5M3MIKx"}},{"cell_type":"markdown","source":["Import Statements\n","---"],"metadata":{"id":"SzRD8waUM0IE"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T4a1vBlCM_h6","executionInfo":{"status":"ok","timestamp":1742997270246,"user_tz":240,"elapsed":17176,"user":{"displayName":"Nicole","userId":"15751869298741229715"}},"outputId":"0dd13520-c3c1-4846-895b-66c07e4be14b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"R8SjlLrek--J","executionInfo":{"status":"ok","timestamp":1742997273006,"user_tz":240,"elapsed":2761,"user":{"displayName":"Nicole","userId":"15751869298741229715"}}},"outputs":[],"source":["import os\n","import pandas as pd\n","import pickle\n","import openpyxl\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"markdown","source":["Select Abundance Data\n","---"],"metadata":{"id":"FIHgCQ3gNwp7"}},{"cell_type":"code","source":["# Specify file path for abundance folder, note /test/ used here; link accordingly\n","# This is proteomic data from a core facility\n","data_dir = '/content/drive/MyDrive/ProteinCoronaPredict_PayneLab/Input_Data/Proteomics/Abundance_Files/'\n","\n","# abundance file options; these are created by Proteomic_Date_Perseus_to_df.ipynb\n","bov_swiss_files = ['Bov_Swiss_Intensity _original.xlsx'] # EDIT: modify list as needed based on file name and proteomics analysis type (i.e. Top3, iBAQ, Intensity)\n","#bov_swiss_trem_files = ['Bov Swiss + TrEMBLE Intensity .csv', 'Bov Swiss + TrEMBLE Top3 .csv', 'Bov Swiss + TrEMBLE iBAQ .csv']\n","\n","# specify which list of abundaces file you want\n","abund_files = bov_swiss_files"],"metadata":{"id":"Dy4aXP8GN28W","executionInfo":{"status":"ok","timestamp":1742997273009,"user_tz":240,"elapsed":1,"user":{"displayName":"Nicole","userId":"15751869298741229715"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Specify file paths to the other data input files\n","\n","\n","*   Control_ file: proteomic reference sample (FBS no NP)\n","*   Biop_file: BioPython precalculations (find in input_data folder)\n","*   NSP_file: NSP precalculations (find in input_data folder)\n","*   NP_file: NP data corresponding to proteomic samples\n","\n","\n","\n"],"metadata":{"id":"sd2u5I6xPOr_"}},{"cell_type":"code","source":["controls_file = '/content/drive/MyDrive/ProteinCoronaPredict_PayneLab/Input_Data/Proteomics/Abundance_Files/controls_FBS_Intensity_v2.xlsx' # for Intensity\n","biop_file = '/content/drive/MyDrive/ProteinCoronaPredict_PayneLab/Input_Data/BioPython/Combined_biopyCalcs.xlsx'\n","nsp_file = '/content/drive/MyDrive/ProteinCoronaPredict_PayneLab/Input_Data/NetSurfP/Combined2.xlsx'\n","np_file = '/content/drive/MyDrive/ProteinCoronaPredict_PayneLab/Input_Data/Nanoparticles/NP_Database_BovOnly_v5.xlsx'"],"metadata":{"id":"bgNzFSQgPNQ3","executionInfo":{"status":"ok","timestamp":1742997273016,"user_tz":240,"elapsed":6,"user":{"displayName":"Nicole","userId":"15751869298741229715"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Read in Excel files in specified paths"],"metadata":{"id":"fsJ4dChTTPo-"}},{"cell_type":"code","source":["controls = pd.read_excel(controls_file, header=0)\n","\n","biop_data = pd.read_excel(biop_file, header=0)\n","biop_data.drop_duplicates(subset=['Entry'], inplace=True)\n","\n","nsp_data = pd.read_excel(nsp_file)\n","nsp_data.drop_duplicates(subset=['Entry'], inplace=True)\n","\n","np_data = pd.read_excel(np_file, header=0)"],"metadata":{"id":"IAe3dBKoTLGD","executionInfo":{"status":"ok","timestamp":1742997355871,"user_tz":240,"elapsed":82854,"user":{"displayName":"Nicole","userId":"15751869298741229715"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Data Merging\n","---"],"metadata":{"id":"BW7j356ySqPd"}},{"cell_type":"code","source":["for prot_file in abund_files:\n","  print(prot_file)\n","  name = prot_file[:-4]\n","  #print(name)\n","  prot_file = data_dir + prot_file\n","  #print(prot_file)\n","\n","  raw_MS_data = pd.read_excel(prot_file, header=0)\n","\n","\n","  raw_MS_data.drop(columns=['prot','prot2','MW'], inplace=True)\n","  raw_MS_data = pd.melt(raw_MS_data, id_vars=['Entry'], var_name='Sample_num', value_name='Abundance')\n","\n","  #Remove proteins that were added due to merge/melt\n","  raw_MS_data.dropna(inplace=True)\n","\n","  #Add abundance controls to the merged MS data\n","  MS_data_controls = pd.merge(raw_MS_data, controls, how='left', on='Entry')\n","\n","  #Merge NetSurfP features and BioPython features\n","  raw_prop_data = pd.merge(MS_data_controls, biop_data, how='left', on='Entry')\n","  protein_data_complete = pd.merge(raw_prop_data, nsp_data, how='left', on='Entry')\n","\n","  #Fill missing data with zeros\n","  protein_data_complete.fillna(0, inplace=True)\n","\n","  #Add NP and wet lab experimental data\n","  protein_data_complete['Sample_num']=protein_data_complete['Sample_num'].astype(str)\n","  np_data[\"Sample_num\"] = np_data[\"Sample_num\"].astype(str)\n","  data_complete = pd.merge(protein_data_complete, np_data, how='inner', on='Sample_num')\n","  data_complete.fillna(0, inplace=True)\n","\n","\n","  #Columns to remove\n","  #From NetSurfP, remove 'exposed' entries and keep 'Exposed_exposed' only\n","  to_drop = data_complete.filter(like='total_exposed_')\n","  data_complete.drop(columns=to_drop, inplace=True)\n","  # columns_to_drop = [\"flexibility_var\",\"flexibility_median\",\"rsa_median\",\"Ligands\",\"Ligand_Carboxylate\",\n","  #                       \"Ligand_BSA\",\"Ligand_Amine\",\"Ligand_Citrate\",\"Ligand_PEG\",\"Ligand_PEI\",\"Ligand_PVP\",\n","  #                       \"Ligand_Au\",\"Shaken\",\"ProteinID\",\"Protein Source\",\"Temperature\", \"Centrifuge\",\n","  #                       \"notes\", \"Notes\"]\n","\n","\n","  columns_to_drop = [\"flexibility_var\",\"flexibility_median\",\"rsa_median\",\"Ligands\",\"Surface_Ligand\",\"Shaken\",\"ProteinID\",\"Protein Source\",\"Temperature\",\n","                        \"notes\", \"Notes\", \"Core Material\", \"Incubation Time (minutes)\", \"Ligands\", \"NPID\", \"Sequence\", \"Raw_FileID\", \"BatchID\", ] # changes made 3/26/25\n","\n","  columns_to_drop = [col for col in columns_to_drop if col in data_complete.columns]\n","  data_complete.drop(columns=columns_to_drop, inplace=True)\n","\n","  #Shuffle data to improve randomization of DataFrame\n","  data_complete = data_complete.sample(frac=1, random_state=42)\n","\n","  #Save as Excel file\n","  # CHANGE TO YOUR NAME CONVENTION\n","  name_specific = 'v1'\n","  filename = f'/content/drive/MyDrive/ProteinCoronaPredict_PayneLab/Input_DataFrames/df_Bov Swiss Intensity_{name_specific}.xlsx'\n","  data_complete.to_excel(filename, index=False)\n","  print('done')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ygrf2C7-Ssq9","executionInfo":{"status":"ok","timestamp":1742997369338,"user_tz":240,"elapsed":13459,"user":{"displayName":"Nicole","userId":"15751869298741229715"}},"outputId":"86124600-4f8e-484c-b475-c767c0aae260"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Bov_Swiss_Intensity _original.xlsx\n","done\n"]}]},{"cell_type":"markdown","source":["The above file(s) is/are the ones that go directly into RFR and RFC Colab notebooks."],"metadata":{"id":"ueBpjL1OdamT"}}]}